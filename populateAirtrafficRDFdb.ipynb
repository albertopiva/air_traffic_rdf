{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Populate Aitraffic RDF database\n",
    "\n",
    "This notebook reports the main steps to download CSV files, process them and create our airtraffic RDF dataset from them accordingly to our ontology. \n",
    "\n",
    "To measure execution time in Jupyter notebooks: <code>pip install ipython-autotime</code>\n",
    "\n",
    "We need to install <code>RDFLib</code>\n",
    "\n",
    "<code>pip3 install rdflib </code> [Documentation](https://rdflib.readthedocs.io/en/stable/gettingstarted.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# required libraries\n",
    "import pandas as pd\n",
    "import os\n",
    "from pathlib import Path\n",
    "import gc\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters and URLs\n",
    "path = str(Path(os.path.abspath(os.getcwd())).absolute())\n",
    "\n",
    "flightsPath = path + '/airtrafficDB/data/flights/'\n",
    "airportsURL = path + '/airtrafficDB/data/airport-codes.csv'\n",
    "aircraftURL = path + '/airtrafficDB/data/aircraft.csv'\n",
    "aircraftTypesURL = path + '/airtrafficDB/data/doc8643AircraftTypes.csv'\n",
    "airlineURL = path + '/airtrafficDB/data/airline.csv'\n",
    "manufacturersURL = path + '/airtrafficDB/data/doc8643Manufacturers.csv'\n",
    "\n",
    "# country codes\n",
    "countriesURL = path + '/airtrafficDB/data/wikipedia-iso-country-codes.csv'\n",
    "\n",
    "#cities codes\n",
    "citiesURL = path + '/airtrafficDB/data/world-cities_csv.csv'\n",
    "\n",
    "# saving folder\n",
    "savePath =  path + '/airtrafficDB/rdf/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the required libraries\n",
    "from rdflib import Graph, Literal, RDF, URIRef, Namespace\n",
    "# rdflib knows about some namespaces, like XSD\n",
    "from rdflib.namespace import XSD\n",
    "\n",
    "# Construct the country and the aitraffic ontology namespaces not known by RDFlib\n",
    "CNS = Namespace(\"http://eulersharp.sourceforge.net/2003/03swap/countries#\")\n",
    "ATO = Namespace(\"http://www.unipd.albertopiva.it/db2/airtrafficOntology#\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flights\n",
    "In this section we model the flights. Since the data we need for the aircrafts are stored in the same file as the flights we also model each aircraft and store them in a separate turtle file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the graph for the flights\n",
    "g = Graph()\n",
    "\n",
    "#create the graph for the aircrafts\n",
    "h = Graph()\n",
    "\n",
    "# Bind the namespaces to a prefix for more readable output\n",
    "g.bind(\"xsd\", XSD)\n",
    "g.bind(\"countries\", CNS)\n",
    "g.bind(\"ato\", ATO)\n",
    "\n",
    "h.bind(\"xsd\", XSD)\n",
    "h.bind(\"countries\", CNS)\n",
    "h.bind(\"ato\", ATO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "#measure execution time\n",
    "#some counters for diagnostics\n",
    "count = 0 \n",
    "prev = 0\n",
    "unkCount = 1 # counter for unkown aircraft\n",
    "cFiles = 1 # counter for output files\n",
    "\n",
    "# We have multiple files for the flights\n",
    "for filename in os.listdir(flightsPath):\n",
    "    \n",
    "    filePath = str(flightsPath) + str(filename)\n",
    "    flights = pd.read_csv(filePath, sep=',', index_col=\"ECTRL ID\")\n",
    "    \n",
    "    print(\"*** START READING FROM FILE \" + str(filename) + \" ***\")\n",
    "    \n",
    "    #iterate over the flights dataframe\n",
    "    for index, row in flights.iterrows():\n",
    "        \n",
    "        # Create the node to add to the Graph\n",
    "        Flight = URIRef(ATO[str(index)])\n",
    "        count+=1\n",
    "        \n",
    "        # Add triples using store's add() method.\n",
    "        g.add((Flight, RDF.type, ATO['Flight']))\n",
    "        # Put timestamps in the right dateTime format\n",
    "        fob = str(row['FILED OFF BLOCK TIME'])\n",
    "        filedOffBlock = datetime.strptime(fob,'%d-%m-%Y %H:%M:%S',).strftime('%Y-%m-%dT%H:%M:%S')\n",
    "        g.add((Flight, ATO['filedOffBlock'], Literal(filedOffBlock, datatype=XSD.dateTime)))\n",
    "        far = str(row['FILED ARRIVAL TIME'])\n",
    "        filedArrival = datetime.strptime(far,'%d-%m-%Y %H:%M:%S',).strftime('%Y-%m-%dT%H:%M:%S')\n",
    "        g.add((Flight, ATO['filedArrival'], Literal(filedArrival, datatype=XSD.dateTime)))\n",
    "        aob = str(row['ACTUAL OFF BLOCK TIME'])\n",
    "        actualOffBlock = datetime.strptime(aob,'%d-%m-%Y %H:%M:%S',).strftime('%Y-%m-%dT%H:%M:%S')\n",
    "        g.add((Flight, ATO['actualOffBlock'], Literal(actualOffBlock, datatype=XSD.dateTime)))\n",
    "        arr = str(row['ACTUAL ARRIVAL TIME'])\n",
    "        actualArrival = datetime.strptime(arr,'%d-%m-%Y %H:%M:%S',).strftime('%Y-%m-%dT%H:%M:%S')\n",
    "        g.add((Flight, ATO['actualArrival'], Literal(actualArrival, datatype=XSD.dateTime)))\n",
    "        \n",
    "        # Add the remaining properties\n",
    "        g.add((Flight, ATO['marketSegment'], Literal(row['STATFOR Market Segment'], datatype=XSD.string)))\n",
    "        g.add((Flight, ATO['distance'], Literal(row['Actual Distance Flown (nm)'], datatype=XSD.integer))) \n",
    "\n",
    "        ## handle airports, discard unknown airports\n",
    "        if(not (str(row['ADEP'])=='ZZZZ')):\n",
    "            Adep = URIRef(ATO[row['ADEP']])\n",
    "            g.add((Flight, ATO['departs'], Adep))  \n",
    "        if(not (str(row['ADES'])=='ZZZZ')):\n",
    "            Ades = URIRef(ATO[row['ADES']])\n",
    "            g.add((Flight, ATO['arrives'], Ades))\n",
    "        \n",
    "        ## handle airline, discard unknown operator\n",
    "        if(not (str(row['AC Operator'])=='ZZZ')):\n",
    "            Airline = URIRef(ATO[row['AC Operator']])\n",
    "            #add the edge connecting the Flight and the Airline performing it\n",
    "            g.add((Flight, ATO['performedBy'], Airline))\n",
    "            \n",
    "        ## Handle aircraft, discard unknwon aircrafts with unknown model \n",
    "        # Check if we have aircraft data\n",
    "        if(not pd.isnull(row['AC Registration'])): \n",
    "            airCode = str(row['AC Registration'])    \n",
    "        # Otherwise we create an unknown aircraft so we can store data about aircraft model    \n",
    "        elif(not (str(row['AC Type'])=='ZZZZ')):  \n",
    "            airCode = \"UNK\" + str(unkCount)\n",
    "            unkCount += 1\n",
    "            \n",
    "        # Create the node to add to the graph   \n",
    "        Aircraft = URIRef(ATO[airCode])\n",
    "        h.add((Aircraft, RDF.type, ATO['Aircraft']))\n",
    "        # Handle aircraft models, discard unknown models\n",
    "        if(not (str(row['AC Type'])=='ZZZZ')):\n",
    "            AircraftModel = URIRef(ATO[row['AC Type']])\n",
    "            #add the edge connecting the Aircraft and its Aircraft model\n",
    "            h.add((Aircraft, ATO['hasType'], AircraftModel))\n",
    "        #add the edge connecting the Flight and the Aircraft performing it\n",
    "        h.add((Aircraft, ATO['performs'], Flight))\n",
    "\n",
    "        ##Diagnostics to keep track of progress\n",
    "        if(count%150000 == 0): print(\"added 150K flights\")\n",
    "        if(count%350000 == 0):\n",
    "            \n",
    "            # we save the output in a ttl file \n",
    "            ttlFname = 'flights' + str(cFiles) + '.ttl'\n",
    "            ttlAname = 'aircrafts' + str(cFiles) + '.ttl'\n",
    "            cFiles+=1\n",
    "            \n",
    "            print(\"--- saving flights serialization in \" + ttlFname + \" ---\")\n",
    "            with open(savePath + ttlFname, 'w') as file:\n",
    "                file.write(g.serialize(format='turtle'))\n",
    "            print(\"--- SAVED ------------------------------------------------\")\n",
    "            \n",
    "            print(\"--- saving aircrafts serialization in \" + ttlAname + \" ---\")\n",
    "            with open(savePath + ttlAname, 'w') as file:\n",
    "                file.write(h.serialize(format='turtle'))\n",
    "            print(\"--- SAVED ------------------------------------------------\")      \n",
    "            # we free some memory\n",
    "            del g\n",
    "            del h\n",
    "            gc.collect()\n",
    "            # we initialize the graphs again to manage memory load\n",
    "            \n",
    "            g = Graph()\n",
    "            g.bind(\"xsd\", XSD)\n",
    "            g.bind(\"countries\", CNS)\n",
    "            g.bind(\"ato\", ATO)\n",
    "            \n",
    "            h = Graph()\n",
    "            h.bind(\"xsd\", XSD)\n",
    "            h.bind(\"countries\", CNS)\n",
    "            h.bind(\"ato\", ATO)\n",
    "            \n",
    "            \n",
    "    print('*** END-OF-FILE: ADDED ' + str(count-prev) + ' FLIGHTS FROM FILE ' + str(filename) + ' ***')        \n",
    "    prev = count\n",
    "        \n",
    "print('***')        \n",
    "print('*** ADDED IN TOTAL ' + str(count) + ' FLIGHTS ***')\n",
    "print('***')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# print the remaining data for the flights in the Turtle format\n",
    "ttlname = 'flights' + str(cFiles) + '.ttl'\n",
    "print(\"--- saving serialization for the last flights ---\")\n",
    "with open(savePath + ttlname, 'w') as file:\n",
    "    file.write(g.serialize(format='turtle'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# print the remaining data for the aircrafts in the Turtle format\n",
    "ttlname = 'aircrafts' + str(cFiles) + '.ttl'\n",
    "print(\"--- saving serialization for the last aircrafts ---\")\n",
    "with open(savePath + ttlname, 'w') as file:\n",
    "    file.write(h.serialize(format='turtle'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Airports and Cities\n",
    "In this section we model the airports and the cities. In order to match efficiently each airport with the correct city we create a dictionary of cities indexed with the iso-code of the country each city belongs to. Then, if we find data about new cities in the airports file we add them to our cities modelling. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indexing the Cities\n",
    "Firstly, we create the dictionary with the cities indexed by country. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CSV files in memory\n",
    "cities = pd.read_csv(citiesURL, sep=',', index_col='geonameid', keep_default_na=False, na_values=['_'])\n",
    "cities.info()\n",
    "countries = pd.read_csv(countriesURL, sep=';', index_col='English short name lower case', keep_default_na=False, na_values=['_'])\n",
    "countries.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creation of the structure\n",
    "citiesByCountry = {}\n",
    "    \n",
    "#iterate over the cities dataframe\n",
    "for index, row in cities.iterrows():\n",
    "    \n",
    "    ## Match country\n",
    "    cName = str(row['country'])\n",
    "    # check if the country exists\n",
    "    # country.index == x returns an array of booleans, thus we need to use the any() method\n",
    "    if((countries.index == cName).any() == True):\n",
    "        #get the country code, convert to string and get the lower case to match the country codes in the contology \n",
    "        code = str(countries[countries.index == cName]['Alpha-2 code'][0]).lower()\n",
    "        if(code not in citiesByCountry): #create a new country before appending the city\n",
    "            citiesByCountry.update({code:[]})\n",
    "        #append the city to the country   \n",
    "        citiesByCountry[code].append([row['name'], \"C\"+str(index)])\n",
    "        \n",
    "print(\"Dictionary Created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Airports Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CSV files in memory\n",
    "airports = pd.read_csv(airportsURL, sep=',', index_col='ident')\n",
    "airports.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a new graph for the airports\n",
    "g = Graph()\n",
    "\n",
    "# Bind the namespaces to a prefix for more readable output\n",
    "g.bind(\"xsd\", XSD)\n",
    "g.bind(\"countries\", CNS)\n",
    "g.bind(\"ato\", ATO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#measure execution time\n",
    "count=0 #counter for diagnostic purpose\n",
    "noMatch=0\n",
    "newCities=[]\n",
    "\n",
    "#iterate over the airports dataframe\n",
    "for index, row in airports.iterrows():\n",
    "    \n",
    "    # Create the node to add to the Graph\n",
    "    Airport = URIRef(ATO[str(index)])\n",
    "    g.add((Airport, RDF.type, ATO['Airport']))\n",
    "    count+=1\n",
    "    \n",
    "    # Add triples using store's add() method.\n",
    "    g.add((Airport, ATO['airportName'], Literal(row['name'], datatype=XSD.string)))\n",
    "    g.add((Airport, ATO['airportType'], Literal(row['type'], datatype=XSD.string)))\n",
    "\n",
    "    ## Handle cities, note that not all airports have data about city\n",
    "    # but every airport that have city data also have iso_country data\n",
    "    if(not pd.isnull(row['municipality'])):\n",
    "        \n",
    "        #strip space and uppercase to avoid mismatching for multiple names cities\n",
    "        cName = str(row['municipality']).replace(\" \",\"\").lower()\n",
    "        \n",
    "        matched = False\n",
    "        try:\n",
    "            for city in citiesByCountry[str(row['iso_country']).lower()]:\n",
    "                \n",
    "                check = city[0].replace(\" \",\"\").lower() \n",
    "                \n",
    "                if(cName == check):\n",
    "                    \n",
    "                    #create the RDF node\n",
    "                    City = URIRef(ATO[str(city[1])])\n",
    "                    #add the edge connecting the Airport and the City\n",
    "                    g.add((Airport, ATO['located'], City))\n",
    "                    matched = True\n",
    "                    # once we find the correct city there is no need to keep iterating\n",
    "                    break \n",
    "            # no match with existing cities, we create a new city        \n",
    "            if(not matched): \n",
    "                noMatch += 1\n",
    "                newCode = \"N\"+str(noMatch).zfill(6)  \n",
    "                newCities.append([newCode, str(row['municipality']), str(row['iso_country']).lower()])\n",
    "                #create the RDF node\n",
    "                City = URIRef(ATO[newCode])\n",
    "                #add the edge connecting the Airport and the City\n",
    "                g.add((Airport, ATO['located'], City))\n",
    "                \n",
    "                \n",
    "        # We skip airport countries not in the dictionary\n",
    "        except KeyError: continue\n",
    "            \n",
    "    if(count%10000==0): print(\"*** 10K Airports added ***\")\n",
    "               \n",
    "print('***')        \n",
    "print('*** ADDED IN TOTAL ' + str(count) + ' AIRPORTS ***')\n",
    "print('***')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# print all the data in the Turtle format\n",
    "print(\"--- saving serialization ---\")\n",
    "with open(savePath + 'airports.ttl', 'w') as file:\n",
    "    file.write(g.serialize(format='turtle'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cities Modelling\n",
    "We model the cities using the dictionary we already created so we avoid matching again the countries and cities files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a new graph for the cities\n",
    "g = Graph()\n",
    "\n",
    "# Bind the namespaces to a prefix for more readable output\n",
    "g.bind(\"xsd\", XSD)\n",
    "g.bind(\"countries\", CNS)\n",
    "g.bind(\"ato\", ATO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "#measure execution time\n",
    "oldCount=0\n",
    "newCount=0\n",
    "#iterate over the dictionary\n",
    "for country in citiesByCountry:\n",
    "    for city in citiesByCountry[country]:\n",
    "        # Create the node to add to the Graph\n",
    "        City = URIRef(ATO[city[1]])\n",
    "        g.add((City, RDF.type, ATO['City']))\n",
    "        # Add triples using store's add() method.\n",
    "        g.add((City, ATO['cityName'], Literal(city[0], datatype=XSD.string)))\n",
    "        # create the RDF node\n",
    "        Country = URIRef(CNS[country])\n",
    "        # add the edge connecting the City and the Country \n",
    "        g.add((City, ATO['belongsTo'], Country))\n",
    "        oldCount+=1\n",
    "\n",
    "print(\"Modelled \" + str(oldCount) + \" cities from Dictionary\")        \n",
    "\n",
    "#iterate over the list of new cities founded when modelling airports\n",
    "for city in newCities:\n",
    "    # Create the node to add to the Graph\n",
    "        City = URIRef(ATO[city[0]])\n",
    "        g.add((City, RDF.type, ATO['City']))\n",
    "        # Add triples using store's add() method.\n",
    "        g.add((City, ATO['cityName'], Literal(city[1], datatype=XSD.string)))\n",
    "        # create the RDF node\n",
    "        Country = URIRef(CNS[city[2]])\n",
    "        # add the edge connecting the City and the Country \n",
    "        g.add((City, ATO['belongsTo'], Country))\n",
    "        newCount+=1\n",
    "\n",
    "print(\"Modelled \" + str(newCount) + \" cities from AIRPORTS\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# print all the data in the Turtle format\n",
    "print(\"--- saving serialization ---\")\n",
    "with open(savePath + 'cities.ttl', 'w') as file:\n",
    "    file.write(g.serialize(format='turtle'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AircraftModel\n",
    "In this section we model the Aircraft Models. We have to consider two file:\n",
    "- the first one gives me the name and the numberOfSeats;\n",
    "- the second one gives me information about engine and manufacturer code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CSV files in memory\n",
    "ac_model = pd.read_csv(aircraftURL, sep=';',header=None, index_col=1).dropna()\n",
    "ac_model.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the graph\n",
    "g = Graph()\n",
    "\n",
    "# Bind the namespaces to a prefix for more readable output\n",
    "g.bind(\"xsd\", XSD)\n",
    "g.bind(\"countries\", CNS)\n",
    "g.bind(\"ato\", ATO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "#measure execution time\n",
    "\n",
    "#iterate over the aircraft-model dataframe\n",
    "for index, row in ac_model.iterrows():\n",
    "    if index == \"\\\\N\" or index == \"N/A\" :\n",
    "        continue\n",
    "    # Create the node to add to the Graph\n",
    "    Aircraft = URIRef(ATO[index])\n",
    "    \n",
    "    # Add triples using store's add() method.\n",
    "    g.add((Aircraft, RDF.type, ATO['AircraftModel']))   \n",
    "    g.add((Aircraft, ATO['modelName'], Literal(row[0], datatype=XSD.string)))\n",
    "    if not (row[3] == \"\\\\N\" or row[3] == \"N/A\" ):\n",
    "        g.add((Aircraft, ATO['numberOfSeats'], Literal(row[3], datatype=XSD.integer)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CSV files in memory\n",
    "ac_type = pd.read_csv(aircraftTypesURL, sep=',', index_col='Designator').dropna()\n",
    "ac_type.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "#measure execution time\n",
    "\n",
    "#iterate over the aircraft-model dataframe\n",
    "for index, row in ac_type.iterrows():\n",
    "    if index == \"\\\\N\" or index == \"N/A\" :\n",
    "        continue\n",
    "    # Create the node to add to the Graph\n",
    "    Aircraft = URIRef(ATO[index])\n",
    "    \n",
    "    #Add triples about engine information\n",
    "    g.add((Aircraft, ATO['engineType'], Literal(row['EngineType'], datatype=XSD.string)))\n",
    "    if(row['EngineCount'] != \"C\"): #Add triple only if EngineCount is a number\n",
    "        g.add((Aircraft, ATO['engineCount'], Literal(row['EngineCount'], datatype=XSD.integer)))\n",
    "    \n",
    "    \n",
    "    #find the manufacturer\n",
    "    man = row['ManufacturerCode'].replace(\" \",\"\").replace(\"(\",\"\").replace(\")\",\"\")\n",
    "    Manufacturer = URIRef(ATO[man])\n",
    "    g.add((Aircraft, ATO['builtBy'], Manufacturer))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# print all the data in the Turtle format\n",
    "print(\"--- saving serialization ---\")\n",
    "with open(savePath + 'aircraft-models.ttl', 'w') as file:\n",
    "    file.write(g.serialize(format='turtle'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manufacturers \n",
    "In this section we model the Manufacturers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CSV files in memory\n",
    "manufacturers = pd.read_csv(manufacturersURL, sep=',', index_col='Code').dropna()\n",
    "manufacturers.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the country codes\n",
    "# we need to convert NaN values to something else otherwise NA strings are converted to NaN -> problem with Namibia\n",
    "countries = pd.read_csv(countriesURL, sep=';', index_col='English short name lower case', keep_default_na=False, na_values=['_'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the graph\n",
    "g = Graph()\n",
    "\n",
    "# Bind the namespaces to a prefix for more readable output\n",
    "g.bind(\"xsd\", XSD)\n",
    "g.bind(\"countries\", CNS)\n",
    "g.bind(\"ato\", ATO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#measure execution time\n",
    "\n",
    "#iterate over the manifacturers dataframe\n",
    "for index, row in manufacturers.iterrows():\n",
    "    \n",
    "    if index == \"(any manufacturer)\" or row['Name'].startswith(\"see\"):\n",
    "        continue\n",
    "        \n",
    "    # Create the node to add to the Graph\n",
    "    ind = index.replace(\" \",\"\").replace(\"(\",\"\").replace(\")\",\"\")\n",
    "    Manufacturer = URIRef(ATO[ind])\n",
    "    \n",
    "    # Add triples using store's add() method.\n",
    "    g.add((Manufacturer, RDF.type, ATO.Manufacturer))\n",
    "\n",
    "    #Handle the name of the manufacturer \n",
    "    splits = row['Name'].split(\"(\")\n",
    "    name = splits[0].strip()\n",
    "    #add the code and the full name\n",
    "    g.add((Manufacturer, ATO['manufacturerName'], Literal(name, datatype=XSD.string)))\n",
    "    \n",
    "    # Handle country, find the alpha-2 code of the country\n",
    "    country = splits[1].replace(\")\",\"\").strip()\n",
    "    for ind,cntr in countries.iterrows():\n",
    "        if ind.lower() == country.lower():\n",
    "            Country = URIRef(CNS[cntr['Alpha-2 code']])\n",
    "            g.add((Manufacturer, ATO['hasNationality'], Country))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# print all the data in the Turtle format\n",
    "print(\"--- saving serialization ---\")\n",
    "with open(savePath + 'manufacturers.ttl', 'w') as file:\n",
    "    file.write(g.serialize(format='turtle'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Airline Companies\n",
    "In this section we model the Airline Companies. We need to consider an important aspect for reading the file:\n",
    "- the csv file about airline does not have the header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CSV files in memory\n",
    "airline = pd.read_csv(airlineURL, sep=',', index_col='ICAO').dropna()\n",
    "airline.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the graph\n",
    "g = Graph()\n",
    "\n",
    "# Bind the namespaces to a prefix for more readable output\n",
    "g.bind(\"xsd\", XSD)\n",
    "g.bind(\"countries\", CNS)\n",
    "g.bind(\"ato\", ATO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "#measure execution time\n",
    "\n",
    "lista = []\n",
    "dupl=[]\n",
    "#iterate over the airline dataframe\n",
    "for index, row in airline.iterrows():\n",
    "    if index == \"nan\" or str(index).strip() == \"\":\n",
    "        continue\n",
    "    if index not in lista:\n",
    "        lista.append(index)\n",
    "        # Create the node to add to the Graph\n",
    "        Airline = URIRef(ATO[str(index).strip()])\n",
    "        # Add triples using store's add() method.\n",
    "        g.add((Airline, RDF.type, ATO.Airline))\n",
    "        # Add the code and the full name\n",
    "        g.add((Airline, ATO['airlineName'], Literal(row['Airline'], datatype=XSD.string)))\n",
    "\n",
    "        # Handle countries, find the alpha-2 code of the country\n",
    "        country = row['Country/Region']\n",
    "        for ind,cntr in countries.iterrows():\n",
    "            if ind.lower() == country.lower():\n",
    "                Country = URIRef(CNS[cntr['Alpha-2 code']])\n",
    "                g.add((Airline, ATO['hasNationality'], Country))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# print all the data in the Turtle format\n",
    "print(\"--- saving serialization ---\")\n",
    "with open(savePath + 'airlines.ttl', 'w') as file:\n",
    "    file.write(g.serialize(format='turtle'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
